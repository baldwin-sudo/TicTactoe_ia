{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux de Neurones Convolutifs : Étape par Étape (avec solution)\n",
    "\n",
    "Bienvenue dans le premier devoir du cours 4 ! Dans cet exercice, vous allez implémenter des couches convolutionnelles (CONV) et de pooling (POOL) en numpy, en incluant à la fois la propagation avant et (facultativement) la rétropropagation.  \n",
    "\n",
    "À la fin de ce notebook, vous serez capable de : \n",
    "\n",
    "* Expliquer l'opération de convolution  \n",
    "* Appliquer deux types différents d'opérations de pooling  \n",
    "* Identifier les composants utilisés dans un réseau de neurones convolutionnels (padding, stride, filtre, ...) et comprendre leur rôle  \n",
    "* Construire un réseau de neurones convolutionnel  \n",
    "\n",
    "**Notations** :\n",
    "- Le **superscrit** $[l]$ désigne un objet de la $l^{ème}$ couche.  \n",
    "    - Exemple : $a^{[4]}$ est l'activation de la $4^{ème}$ couche. $W^{[5]}$ et $b^{[5]}$ sont les paramètres de la $5^{ème}$ couche.\n",
    "\n",
    "- Le **superscrit** $(i)$ désigne un objet provenant du $i^{ème}$ exemple.  \n",
    "    - Exemple : $x^{(i)}$ est l'entrée du $i^{ème}$ exemple d'entraînement.  \n",
    "\n",
    "- Le **subscript** $i$ désigne la $i^{ème}$ entrée d'un vecteur.  \n",
    "    - Exemple : $a^{[l]}_i$ désigne la $i^{ème}$ entrée des activations dans la couche $l$, en supposant qu'il s'agit d'une couche entièrement connectée (FC).  \n",
    "\n",
    "- $n_H$, $n_W$ et $n_C$ désignent respectivement la hauteur, la largeur et le nombre de canaux d'une couche donnée. Si vous voulez faire référence à une couche spécifique $l$, vous pouvez également écrire $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$.  \n",
    "- $n_{H_{prev}}$, $n_{W_{prev}}$ et $n_{C_{prev}}$ désignent respectivement la hauteur, la largeur et le nombre de canaux de la couche précédente. Si vous faites référence à une couche spécifique $l$, cela pourrait également être noté $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$.  \n",
    "\n",
    "Vous devriez être à l'aise avec `numpy` et/ou avoir suivi les cours précédents de cette spécialisation. Commençons !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des Matières\n",
    "\n",
    "- [1 - Bibliothèques](#1)  \n",
    "- [2 - Aperçu de l'exercice](#2)  \n",
    "- [3 - Réseaux de Neurones Convolutifs](#3)  \n",
    "    - [3.1 - Zero-Padding (Remplissage par Zéros)](#3-1)  \n",
    "        - [Exercice 1 - zero_pad](#ex-1)  \n",
    "    - [3.2 - Étape Unique de Convolution](#3-2)  \n",
    "        - [Exercice 2 - conv_single_step](#ex-2)  \n",
    "    - [3.3 - Réseaux de Neurones Convolutifs - Propagation Avant](#3-3)  \n",
    "        - [Exercice 3 - conv_forward](#ex-3)  \n",
    "- [4 - Couche de Pooling](#4)  \n",
    "    - [4.1 - Pooling Avant](#4-1)  \n",
    "        - [Exercice 4 - pool_forward](#ex-4)  \n",
    "- [5 - Rétropropagation dans les Réseaux de Neurones Convolutifs (OPTIONNEL / NON NOTÉ)](#5)  \n",
    "    - [5.1 - Couche de Convolution - Rétropropagation](#5-1)  \n",
    "        - [5.1.1 - Calcul de dA](#5-1-1)  \n",
    "        - [5.1.2 - Calcul de dW](#5-1-2)  \n",
    "        - [5.1.3 - Calcul de db](#5-1-3)  \n",
    "            - [Exercice 5 - conv_backward](#ex-5)  \n",
    "    - [5.2 - Couche de Pooling - Rétropropagation](#5-2)  \n",
    "        - [5.2.1 - Pooling Maximal - Rétropropagation](#5-2-1)  \n",
    "            - [Exercice 6 - create_mask_from_window](#ex-6)  \n",
    "        - [5.2.2 - Pooling Moyenne - Rétropropagation](#5-2-2)  \n",
    "            - [Exercice 7 - distribute_value](#ex-7)  \n",
    "        - [5.2.3 - Regroupement : Pooling Rétropropagation](#5-2-3)  \n",
    "            - [Exercice 8 - pool_backward](#ex-8)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>  \n",
    "## 1 - Bibliothèques  \n",
    "\n",
    "Commençons par importer toutes les bibliothèques dont vous aurez besoin pour cet exercice.  \n",
    "- [numpy](www.numpy.org) est la bibliothèque fondamentale pour le calcul scientifique avec Python.  \n",
    "- [matplotlib](http://matplotlib.org) est une bibliothèque pour tracer des graphiques en Python.  \n",
    "- `np.random.seed(1)` est utilisé pour maintenir la cohérence de toutes les fonctions aléatoires appelées. Cela facilite l'évaluation de votre travail.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>  \n",
    "## 2 - Aperçu de l'Exercice  \n",
    "\n",
    "Vous allez implémenter les blocs de construction d'un réseau de neurones convolutionnel ! Chaque fonction que vous allez coder comportera des instructions détaillées pour vous guider à travers les étapes :  \n",
    "\n",
    "- Fonctions de convolution, y compris :  \n",
    "    - Zero Padding (remplissage par zéros)  \n",
    "    - Fenêtre de convolution  \n",
    "    - Propagation avant pour la convolution  \n",
    "    - Rétropropagation pour la convolution (optionnelle)  \n",
    "- Fonctions de pooling, y compris :  \n",
    "    - Propagation avant pour le pooling  \n",
    "    - Création de masque  \n",
    "    - Distribution des valeurs  \n",
    "    - Rétropropagation pour le pooling (optionnelle)  \n",
    "\n",
    "Ce notebook vous demandera d'implémenter ces fonctions à partir de zéro en utilisant `numpy`. Dans le prochain notebook, vous utiliserez les équivalents de ces fonctions dans TensorFlow pour construire le modèle suivant :  \n",
    "\n",
    "<img src=\"images/model.png\" style=\"width:800px;height:300px;\">  \n",
    "\n",
    "**Remarque** : Pour chaque fonction de propagation avant, il existe un équivalent en rétropropagation. Ainsi, à chaque étape de votre module de propagation avant, vous stockerez certains paramètres dans un cache. Ces paramètres seront utilisés pour calculer les gradients lors de la rétropropagation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>  \n",
    "## 3 - Réseaux de Neurones Convolutifs  \n",
    "\n",
    "Bien que les frameworks de programmation rendent les convolutions faciles à utiliser, elles restent l’un des concepts les plus difficiles à comprendre en apprentissage profond. Une couche de convolution transforme un volume d'entrée en un volume de sortie de taille différente, comme illustré ci-dessous.  \n",
    "\n",
    "<img src=\"images/conv_nn.png\" style=\"width:350px;height:200px;\">  \n",
    "\n",
    "Dans cette partie, vous allez construire chaque étape de la couche de convolution. Vous commencerez par implémenter deux fonctions auxiliaires : une pour le remplissage par zéros (zero padding) et une autre pour le calcul de la fonction de convolution elle-même.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>  \n",
    "### 3.1 - Remplissage par Zéros (Zero-Padding)  \n",
    "\n",
    "Le remplissage par zéros ajoute des zéros autour de la bordure d'une image :  \n",
    "\n",
    "<img src=\"images/PAD.png\" style=\"width:600px;height:400px;\">  \n",
    "<caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><font color='purple'> : <b>Zero-Padding</b><br> Image (3 canaux, RGB) avec un padding de 2. </center></caption>  \n",
    "\n",
    "Les principaux avantages du padding sont :  \n",
    "\n",
    "- Il permet d'utiliser une couche de convolution (CONV) sans nécessairement réduire la hauteur et la largeur des volumes. Cela est important pour construire des réseaux plus profonds, car sinon la hauteur/largeur diminuerait à mesure que l'on passe aux couches plus profondes. Un cas particulier important est la convolution dite \"same\", où la hauteur/largeur est exactement préservée après une couche.  \n",
    "\n",
    "- Il permet de conserver davantage d'informations sur les bordures d'une image. Sans padding, très peu de valeurs dans la couche suivante seraient influencées par les pixels situés aux bords d'une image.  \n",
    "\n",
    "<a name='ex-1'></a>  \n",
    "### Exercice 1 - zero_pad  \n",
    "Implémentez la fonction suivante, qui ajoute un remplissage par zéros à toutes les images d'un lot d'exemples \\(X\\). [Utilisez np.pad](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html). Notez que si vous souhaitez remplir un tableau `a` de forme \\((5, 5, 5, 5, 5)\\) avec `pad = 1` pour la 2e dimension, `pad = 3` pour la 4e dimension, et `pad = 0` pour les autres, vous feriez :  \n",
    "\n",
    "```python  \n",
    "\n",
    "a = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), mode='constant', constant_values = (0,0))  \n",
    "\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a14748505131e4100f550b8afcfb2d33",
     "grade": false,
     "grade_id": "cell-3096786c4bcad84a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: zero_pad\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Ajoute un remplissage de zéros à toutes les images du jeu de données X. Le remplissage est appliqué \n",
    "    à la hauteur et à la largeur de chaque image, comme illustré dans la Figure 1.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- tableau numpy de forme (m, n_H, n_W, n_C) représentant un lot de m images\n",
    "    pad -- entier, quantité de remplissage autour de chaque image sur les dimensions verticales et horizontales\n",
    "    \n",
    "    Retourne:\n",
    "    X_pad -- image remplie de forme (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # (≈ 1 ligne de code)\n",
    "    # X_pad = None\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode='constant', constant_values=0)\n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    return X_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f57532552ae25bcf8ab6b888298349dd",
     "grade": true,
     "grade_id": "cell-65f1ed75ba39bc0a",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      " (4, 3, 3, 2)\n",
      "x_pad.shape =\n",
      " (4, 9, 9, 2)\n",
      "x[1,1] =\n",
      " [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] =\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 3)\n",
    "print (\"x.shape =\\n\", x.shape)\n",
    "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
    "print (\"x[1,1] =\\n\", x[1, 1])\n",
    "print (\"x_pad[1,1] =\\n\", x_pad[1, 1])\n",
    "\n",
    "assert type(x_pad) == np.ndarray, \"Output must be a np array\"\n",
    "assert x_pad.shape == (4, 9, 9, 2), f\"Wrong shape: {x_pad.shape} != (4, 9, 9, 2)\"\n",
    "print(x_pad[0, 0:2,:, 0])\n",
    "assert np.allclose(x_pad[0, 0:2,:, 0], [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]], 1e-15), \"Rows are not padded with zeros\"\n",
    "assert np.allclose(x_pad[0, :, 7:9, 1].transpose(), [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]], 1e-15), \"Columns are not padded with zeros\"\n",
    "assert np.allclose(x_pad[:, 3:6, 3:6, :], x, 1e-15), \"Internal values are different\"\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0, :, :, 0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0, :, :, 0])\n",
    "zero_pad_test(zero_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici la traduction en français de votre texte :\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 - Une étape de convolution\n",
    "\n",
    "Dans cette partie, vous allez implémenter une seule étape de convolution, dans laquelle vous appliquez le filtre à une seule position de l'entrée. Cela sera utilisé pour construire une unité de convolution, qui :\n",
    "\n",
    "- Prend un volume d'entrée\n",
    "- Applique un filtre à chaque position de l'entrée\n",
    "- Produit un autre volume (généralement de taille différente)\n",
    "\n",
    "<img src=\"images/Convolution_schematic.gif\" style=\"width:500px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 2</b> </u><font color='purple'>  : <b>Opération de convolution</b><br> avec un filtre de 3x3 et un pas (stride) de 1 (le pas désigne le nombre de positions que vous déplacez la fenêtre à chaque fois) </center></caption>\n",
    "\n",
    "Dans une application de vision par ordinateur, chaque valeur dans la matrice à gauche correspond à la valeur d'un seul pixel. Vous convoluez un filtre 3x3 avec l'image en multipliant ses valeurs élément par élément avec la matrice d'origine, puis en les additionnant et en ajoutant un biais. Dans cette première étape de l'exercice, vous allez implémenter une seule étape de convolution, correspondant à l'application d'un filtre à l'une des positions afin d'obtenir une sortie unique de type réel.\n",
    "\n",
    "Plus tard dans ce cahier, vous appliquerez cette fonction à plusieurs positions de l'entrée pour implémenter l'opération de convolution complète.\n",
    "\n",
    "### Exercice 2 - `conv_single_step`\n",
    "Implémentez `conv_single_step()`.\n",
    "\n",
    "[Indice](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : La variable `b` sera passée sous forme de tableau numpy. Si vous ajoutez un scalaire (un nombre à virgule flottante ou un entier) à un tableau numpy, le résultat sera un tableau numpy. Dans le cas particulier d'un tableau numpy contenant une seule valeur, vous pouvez le convertir en un scalaire en le castant en `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ef959e74c801cce52d46fb16fb0ba0d",
     "grade": false,
     "grade_id": "cell-bd1b8f799894d4e0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_single_step\n",
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Applique un filtre défini par les paramètres W sur une seule tranche (a_slice_prev) de l'activation de sortie \n",
    "    de la couche précédente.\n",
    "    \n",
    "    Arguments :\n",
    "    a_slice_prev -- tranche des données d'entrée de forme (f, f, n_C_prev)\n",
    "    W -- Paramètres de poids contenus dans une fenêtre - matrice de forme (f, f, n_C_prev)\n",
    "    b -- Paramètres de biais contenus dans une fenêtre - matrice de forme (1, 1, 1)\n",
    "    \n",
    "    Retourne :\n",
    "    Z -- une valeur scalaire, le résultat de la convolution de la fenêtre glissante (W, b) sur une tranche x des données d'entrée\n",
    "    \"\"\"\n",
    "\n",
    "    #(≈ 3 lignes de code)\n",
    "    # Produit élément par élément entre a_slice_prev et W. Ne pas ajouter encore le biais.\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    # Somme de toutes les entrées du volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Ajouter le biais b à Z. Convertir b en float() pour que Z soit une valeur scalaire.\n",
    "    b = np.squeeze(b)\n",
    "    Z = Z + b\n",
    "\n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "794e89cc8202e83b9752d097a4c0d730",
     "grade": true,
     "grade_id": "cell-a77e63b4119ac3b9",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)\n",
    "conv_single_step_test(conv_single_step)\n",
    "\n",
    "assert (type(Z) == np.float64 or type(Z) == np.float32), \"You must cast the output to float\"\n",
    "assert np.isclose(Z, -6.999089450680221), \"Wrong value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traduction en français :**\n",
    "\n",
    "<a name='3-3'></a>\n",
    "### 3.3 - Réseaux de Neurones Convolutionnels - Pass Forward\n",
    "\n",
    "Dans le passage forward, vous utiliserez plusieurs filtres et les appliquerez (convoluerez) sur l'entrée. Chaque 'convolution' vous donne une sortie sous forme de matrice 2D. Vous empilerez ensuite ces sorties pour obtenir un volume 3D :\n",
    "\n",
    "\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercice 3 -  conv_forward\n",
    "Implémentez la fonction ci-dessous pour convoluer les filtres `W` sur une activation d'entrée `A_prev`.  \n",
    "Cette fonction prend les entrées suivantes :\n",
    "* `A_prev`, les activations produites par la couche précédente (pour un lot de m entrées) ; \n",
    "* Les poids sont représentés par `W`. La taille de la fenêtre du filtre est `f` par `f`.\n",
    "* Le vecteur de biais est `b`, où chaque filtre a son propre (unique) biais. \n",
    "\n",
    "Vous avez également accès au dictionnaire des hyperparamètres, qui contient le stride (pas) et le padding (remplissage). \n",
    "\n",
    "**Astuce** : \n",
    "1. Pour sélectionner une tranche 2x2 dans le coin supérieur gauche d'une matrice \"a_prev\" (forme (5,5,3)), vous feriez :\n",
    "```python\n",
    "a_slice_prev = a_prev[0:2,0:2,:]\n",
    "```\n",
    "Notez que cela donne une tranche 3D de hauteur 2, largeur 2 et profondeur 3. La profondeur correspond au nombre de canaux.  \n",
    "Cela vous sera utile lorsque vous définirez `a_slice_prev` ci-dessous, en utilisant les index de départ/fin que vous définirez.\n",
    "\n",
    "2. Pour définir une tranche (`a_slice`), vous devrez d'abord définir ses coins `vert_start`, `vert_end`, `horiz_start` et `horiz_end`. Cette figure pourrait vous être utile pour comprendre comment chaque coin peut être défini à l'aide des variables `h`, `w`, `f` et `s` dans le code ci-dessous.\n",
    "\n",
    "<img src=\"images/vert_horiz_kiank.png\" style=\"width:400px;height:300px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 3</b> </u><font color='purple'>  : <b>Définition d'une tranche en utilisant les indices de début/fin verticaux et horizontaux (avec un filtre 2x2)</b> <br> Cette figure montre uniquement un seul canal.  </center></caption>\n",
    "\n",
    "\n",
    "**Rappel** :\n",
    "    \n",
    "Les formules reliant la forme de la sortie de la convolution à la forme de l'entrée sont :\n",
    "\n",
    "$$n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1$$\n",
    "$$n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1$$\n",
    "$$n_C = \\text{nombre de filtres utilisés dans la convolution}$$\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Pour cet exercice, ne vous préoccupez pas de la vectorisation ! Implémentez tout avec des boucles `for`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Astuces supplémentaires (si vous êtes bloqué) :\n",
    "\n",
    "* Utilisez le découpage de tableaux (par exemple `varname[0:1,:,3:5]`) pour les variables suivantes :  \n",
    "  `a_prev_pad`, `W`, `b`  \n",
    "  - Copiez le code de départ de la fonction et exécutez-le à l'extérieur de la fonction définie, dans des cellules séparées.  \n",
    "  - Vérifiez que le sous-ensemble de chaque tableau correspond à la taille et à la dimension attendues.  \n",
    "* Pour déterminer comment obtenir les indices `vert_start`, `vert_end`, `horiz_start`, `horiz_end`, rappelez-vous que ce sont les indices de la couche précédente.  \n",
    "  - Dessinez un exemple de couche précédente avec un remplissage (8 x 8, par exemple), et la couche actuelle (couche de sortie) (2 x 2, par exemple).  \n",
    "  - Les indices de la couche de sortie sont notés par `h` et `w`.  \n",
    "* Assurez-vous que `a_slice_prev` a une hauteur, une largeur et une profondeur.\n",
    "* Rappelez-vous que `a_prev_pad` est un sous-ensemble de `A_prev_pad`.  \n",
    "  - Réfléchissez à laquelle des deux vous devez utiliser dans les boucles `for`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "812d5c174c04b75b9edaf9b77ce3da72",
     "grade": false,
     "grade_id": "cell-00b35b01091c3cdc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_forward\n",
    "\n",
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implémente la propagation avant pour une fonction de convolution.\n",
    "    \n",
    "    Arguments :\n",
    "    A_prev -- activations de sortie de la couche précédente, \n",
    "        tableau numpy de forme (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Poids, tableau numpy de forme (f, f, n_C_prev, n_C)\n",
    "    b -- Biais, tableau numpy de forme (1, 1, 1, n_C)\n",
    "    hparameters -- dictionnaire python contenant \"stride\" et \"pad\"\n",
    "        \n",
    "    Retourne :\n",
    "    Z -- sortie de la convolution, tableau numpy de forme (m, n_H, n_W, n_C)\n",
    "    cache -- cache des valeurs nécessaires pour la fonction conv_backward()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Récupérer les dimensions de A_prev (≈1 ligne)  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Récupérer les dimensions de W (≈1 ligne)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Récupérer les informations de \"hparameters\" (≈2 lignes)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Calculer les dimensions du volume de sortie CONV en utilisant la formule donnée ci-dessus. \n",
    "    # Astuce : utiliser int() pour appliquer l'opération \"floor\". (≈2 lignes)\n",
    "    n_H = int((n_H_prev + 2*pad - f)/stride) + 1\n",
    "    n_W = int((n_W_prev + 2*pad - f)/stride) + 1\n",
    "    \n",
    "    # Initialiser le volume de sortie Z avec des zéros. (≈1 ligne)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Créer A_prev_pad en ajoutant du remplissage à A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):               # boucle sur le lot d'exemples d'entraînement\n",
    "        a_prev_pad = A_prev_pad[i]          # Sélectionner l'activation remplie du i-ème exemple d'entraînement\n",
    "        for h in range(n_H):           # boucle sur l'axe vertical du volume de sortie\n",
    "            # Trouver les indices de début et de fin verticaux du \"slice\" actuel (≈2 lignes)\n",
    "            vert_start = stride * h \n",
    "            vert_end = vert_start  + f\n",
    "            \n",
    "            for w in range(n_W):       # boucle sur l'axe horizontal du volume de sortie\n",
    "                # Trouver les indices de début et de fin horizontaux du \"slice\" actuel (≈2 lignes)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range(n_C):   # boucle sur les canaux (= #filtres) du volume de sortie\n",
    "                                        \n",
    "                    # Utiliser les coins pour définir le \"slice\" (3D) de a_prev_pad (voir astuce ci-dessus). (≈1 ligne)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    \n",
    "                    # Convoluer le \"slice\" (3D) avec le bon filtre W et le biais b, pour obtenir un neurone de sortie. (≈3 lignes)\n",
    "                    weights = W[:, :, :, c]\n",
    "                    biases  = b[:, :, :, c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "    \n",
    "    # Sauvegarder les informations dans \"cache\" pour la rétropropagation\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3dea502cdd13258e8b23dbb0a19402a",
     "grade": true,
     "grade_id": "cell-429520eed87675d9",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean =\n",
      " 0.5511276474566768\n",
      "Z[0,2,1] =\n",
      " [-2.17796037  8.07171329 -0.5772704   3.36286738  4.48113645 -2.89198428\n",
      " 10.99288867  3.03171932]\n",
      "cache_conv[0][1][2][3] =\n",
      " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 7, 4)\n",
    "W = np.random.randn(3, 3, 4, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\\n\", np.mean(Z))\n",
    "print(\"Z[0,2,1] =\\n\", Z[0, 2, 1])\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])\n",
    "\n",
    "conv_forward_test(conv_forward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Enfin, une couche CONV devrait également contenir une activation, auquel cas vous ajouteriez la ligne de code suivante :\n",
    "\n",
    "```python\n",
    "# Convoluer la fenêtre pour obtenir un neurone de sortie\n",
    "Z[i, h, w, c] = ...\n",
    "# Appliquer l'activation\n",
    "A[i, h, w, c] = activation(Z[i, h, w, c])\n",
    "```\n",
    "\n",
    "Cependant, il n'est pas nécessaire de le faire ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4 - Couche de Pooling\n",
    "\n",
    "La couche de pooling (POOL) réduit la hauteur et la largeur de l'entrée. Cela aide à réduire la computation, tout en rendant les détecteurs de caractéristiques plus invariants à leur position dans l'entrée. Les deux types de couches de pooling sont :\n",
    "\n",
    "- **Max-pooling** : fait glisser une fenêtre de taille ($f, f$) sur l'entrée et stocke la valeur maximale de la fenêtre dans la sortie.\n",
    "  \n",
    "- **Average-pooling** : fait glisser une fenêtre de taille ($f, f$) sur l'entrée et stocke la valeur moyenne de la fenêtre dans la sortie.\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/max_pool1.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "\n",
    "<td>\n",
    "<img src=\"images/a_pool.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "</table>\n",
    "\n",
    "Ces couches de pooling n'ont pas de paramètres pour la rétropropagation à entraîner. Cependant, elles ont des hyperparamètres tels que la taille de la fenêtre $f$. Cela spécifie la hauteur et la largeur de la fenêtre $f \\times f$ sur laquelle vous calculeriez un *max* ou une *moyenne*.\n",
    "\n",
    "### 4.1 - Pooling Avant\n",
    "\n",
    "Maintenant, vous allez implémenter MAX-POOL et AVG-POOL dans la même fonction.\n",
    "\n",
    "### Exercice 4 - pool_forward\n",
    "\n",
    "Implémentez le passage avant de la couche de pooling. Suivez les indices dans les commentaires ci-dessous.\n",
    "\n",
    "**Rappel** :\n",
    "Comme il n'y a pas de padding, les formules reliant la forme de sortie du pooling à la forme de l'entrée sont les suivantes :\n",
    "\n",
    "$$n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f}{stride} \\Bigr\\rfloor +1$$\n",
    "\n",
    "$$n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - f}{stride} \\Bigr\\rfloor +1$$\n",
    "\n",
    "$$n_C = n_{C_{prev}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0201a499bc4a2249c65fa3a736985fac",
     "grade": false,
     "grade_id": "cell-aed533a126205ca2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pool_forward\n",
    "\n",
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implémente le passage avant de la couche de pooling\n",
    "    \n",
    "    Arguments :\n",
    "    A_prev -- Données d'entrée, tableau numpy de forme (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- dictionnaire python contenant \"f\" et \"stride\"\n",
    "    mode -- le mode de pooling que vous souhaitez utiliser, défini comme une chaîne de caractères (\"max\" ou \"average\")\n",
    "    \n",
    "    Retourne :\n",
    "    A -- Sortie de la couche de pooling, un tableau numpy de forme (m, n_H, n_W, n_C)\n",
    "    cache -- Cache utilisé dans le passage arrière de la couche de pooling, contient l'entrée et les hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Récupérer les dimensions de la forme de l'entrée\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Récupérer les hyperparamètres depuis \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Définir les dimensions de la sortie\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialiser la matrice de sortie A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    ### DÉBUT DU CODE ###\n",
    "    for i in range(m):                         # boucle sur les exemples d'entraînement\n",
    "        a_prev_slice = A_prev[i]\n",
    "        for h in range(n_H):                     # boucle sur l'axe vertical de la sortie\n",
    "            # Trouver les indices de début et de fin verticaux du \"slice\" actuel (≈2 lignes)\n",
    "            vert_start = stride * h \n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):                 # boucle sur l'axe horizontal de la sortie\n",
    "                # Trouver les indices de début et de fin horizontaux du \"slice\" actuel (≈2 lignes)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range (n_C):            # boucle sur les canaux de la sortie\n",
    "                    \n",
    "                    # Utiliser les coins pour définir le \"slice\" actuel sur le i-ème exemple d'entraînement de A_prev, canal c. (≈1 ligne)\n",
    "                    a_slice_prev = a_prev_slice[vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                    \n",
    "                    # Calculer l'opération de pooling sur le slice. \n",
    "                    # Utiliser une instruction if pour différencier les modes. \n",
    "                    # Utiliser np.max et np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_slice_prev)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_slice_prev)\n",
    "                    else:\n",
    "                        print(mode + \"-type pooling layer NON DEFINI\")    \n",
    "    # FIN DU CODE\n",
    "    \n",
    "    # Stocker l'entrée et les hparameters dans \"cache\" pour pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Vérifier que la forme de la sortie est correcte\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb7e501b042f94e7bd4326dd6e0bed92",
     "grade": true,
     "grade_id": "cell-ae96f27f888cec37",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A[1, 1] =\n",
      " [[1.96710175 0.84616065 1.27375593]\n",
      " [1.96710175 0.84616065 1.23616403]\n",
      " [1.62765075 1.12141771 1.2245077 ]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A[1, 1] =\n",
      " [[ 0.44497696 -0.00261695 -0.31040307]\n",
      " [ 0.50811474 -0.23493734 -0.23961183]\n",
      " [ 0.11872677  0.17255229 -0.22112197]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1, 1] =\\n\", A[1, 1])\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1, 1] =\\n\", A[1, 1])\n",
    "\n",
    "pool_forward_test(pool_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "\n",
    "```\n",
    "mode = max\n",
    "A.shape = (2, 3, 3, 3)\n",
    "A[1, 1] =\n",
    " [[1.96710175 0.84616065 1.27375593]\n",
    " [1.96710175 0.84616065 1.23616403]\n",
    " [1.62765075 1.12141771 1.2245077 ]]\n",
    "\n",
    "mode = average\n",
    "A.shape = (2, 3, 3, 3)\n",
    "A[1, 1] =\n",
    " [[ 0.44497696 -0.00261695 -0.31040307]\n",
    " [ 0.50811474 -0.23493734 -0.23961183]\n",
    " [ 0.11872677  0.17255229 -0.22112197]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "756f8dfdbdba11c66fc0b342d8be23c4",
     "grade": true,
     "grade_id": "cell-2bc34b23ee92311b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A[0] =\n",
      " [[[1.74481176 0.90159072 1.65980218]\n",
      "  [1.74481176 1.6924546  1.65980218]]\n",
      "\n",
      " [[1.13162939 1.51981682 2.18557541]\n",
      "  [1.13162939 1.6924546  2.18557541]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A[1] =\n",
      " [[[-0.17313416  0.32377198 -0.34317572]\n",
      "  [ 0.02030094  0.14141479 -0.01231585]]\n",
      "\n",
      " [[ 0.42944926  0.08446996 -0.27290905]\n",
      "  [ 0.15077452  0.28911175  0.00123239]]]\n"
     ]
    }
   ],
   "source": [
    "# Case 2: stride of 2\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[0] =\\n\", A[0])\n",
    "print()\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A[1] =\\n\", A[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "    \n",
    "```\n",
    "mode = max\n",
    "A.shape = (2, 2, 2, 3)\n",
    "A[0] =\n",
    " [[[1.74481176 0.90159072 1.65980218]\n",
    "  [1.74481176 1.6924546  1.65980218]]\n",
    "\n",
    " [[1.13162939 1.51981682 2.18557541]\n",
    "  [1.13162939 1.6924546  2.18557541]]]\n",
    "\n",
    "mode = average\n",
    "A.shape = (2, 2, 2, 3)\n",
    "A[1] =\n",
    " [[[-0.17313416  0.32377198 -0.34317572]\n",
    "  [ 0.02030094  0.14141479 -0.01231585]]\n",
    "\n",
    " [[ 0.42944926  0.08446996 -0.27290905]\n",
    "  [ 0.15077452  0.28911175  0.00123239]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**Voici ce que vous devez retenir**:\n",
    "\n",
    "* Une convolution extrait des caractéristiques d'une image d'entrée en effectuant un produit scalaire entre les données d'entrée et un tableau 2D de poids (le filtre).\n",
    "* Le résultat 2D de la convolution est appelé la carte de caractéristiques.\n",
    "* Une couche de convolution est l'endroit où le filtre glisse sur l'image et effectue le produit scalaire.\n",
    "    * Cela transforme le volume d'entrée en un volume de sortie de taille différente.\n",
    "* Le *zero padding* permet de conserver plus d'informations aux bords de l'image et est utile pour construire des réseaux plus profonds, car il permet de construire une couche CONV sans réduire la hauteur et la largeur des volumes.\n",
    "* Les couches de pooling réduisent progressivement la hauteur et la largeur de l'entrée en faisant glisser une fenêtre 2D sur chaque région spécifiée, puis en résumant les caractéristiques de cette région."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Félicitations** ! Vous avez maintenant implémenté les passes avant de toutes les couches d'un réseau de convolution. Beau travail !\n",
    "\n",
    "Le reste de ce carnet est optionnel et ne sera pas noté. Si vous continuez, n'oubliez pas de cliquer sur le bouton \"Soumettre\" pour soumettre votre travail pour la notation d'abord."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name='5'></a>\n",
    "## 5 - Rétropropagation dans les réseaux de neurones convolutionnels (OPTIONNEL / NON NOTÉ)\n",
    "\n",
    "Dans les frameworks modernes d'apprentissage profond, vous n'avez qu'à implémenter la passe avant, et le framework s'occupe de la passe arrière, donc la plupart des ingénieurs en apprentissage profond n'ont pas besoin de se soucier des détails de la passe arrière. La passe arrière pour les réseaux convolutionnels est compliquée. Si vous le souhaitez, vous pouvez travailler sur cette portion optionnelle du carnet pour avoir une idée de ce à quoi ressemble la rétropropagation dans un réseau convolutionnel.\n",
    "\n",
    "Lorsque dans un cours précédent vous avez implémenté un réseau de neurones simple (pleinement connecté), vous avez utilisé la rétropropagation pour calculer les dérivées par rapport au coût afin de mettre à jour les paramètres. De même, dans les réseaux neuronaux convolutionnels, vous pouvez calculer les dérivées par rapport au coût afin de mettre à jour les paramètres. Les équations de rétropropagation ne sont pas triviales et n'ont pas été dérivées dans le cours, mais elles sont brièvement présentées ci-dessous.\n",
    "\n",
    "<a name='5-1'></a>\n",
    "### 5.1 - Rétropropagation de la couche convolutionnelle\n",
    "\n",
    "Commençons par implémenter la rétropropagation pour une couche CONV.\n",
    "\n",
    "<a name='5-1-1'></a>\n",
    "#### 5.1.1 - Calcul de dA :\n",
    "Voici la formule pour calculer \\(dA\\) par rapport au coût pour un certain filtre \\(W_c\\) et un exemple d'entraînement donné :\n",
    "\n",
    "$$dA \\mathrel{+}= \\sum _{h=0} ^{n_H} \\sum_{w=0} ^{n_W} W_c \\times dZ_{hw} \\tag{1}$$\n",
    "\n",
    "Où \\(W_c\\) est un filtre et \\(dZ_{hw}\\) est un scalaire correspondant au gradient du coût par rapport à la sortie de la couche conv Z à la h-ième ligne et w-ième colonne (correspondant au produit scalaire pris au i-ème déplacement à gauche et j-ème déplacement vers le bas). Notez qu'à chaque fois, vous multipliez le même filtre \\(W_c\\) par un \\(dZ\\) différent lors de la mise à jour de \\(dA\\). Nous faisons cela principalement parce que lors de la propagation avant, chaque filtre est multiplié et additionné à un \\(a_{\\text{slice}}\\) différent. Par conséquent, lors du calcul de la rétropropagation pour \\(dA\\), vous ajoutez simplement les gradients de tous les \\(a_{\\text{slices}}\\).\n",
    "\n",
    "En code, à l'intérieur des boucles appropriées, cette formule se traduit par :\n",
    "```python\n",
    "da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "```\n",
    "\n",
    "<a name='5-1-2'></a>\n",
    "#### 5.1.2 - Calcul de dW :\n",
    "Voici la formule pour calculer \\(dW_c\\) (où \\(dW_c\\) est la dérivée d'un filtre) par rapport à la perte :\n",
    "\n",
    "$$dW_c  \\mathrel{+}= \\sum _{h=0} ^{n_H} \\sum_{w=0} ^{n_W} a_{\\text{slice}} \\times dZ_{hw}  \\tag{2}$$\n",
    "\n",
    "Où \\(a_{\\text{slice}}\\) correspond à la tranche qui a été utilisée pour générer l'activation \\(Z_{ij}\\). Ainsi, cela nous donne le gradient pour \\(W\\) par rapport à cette tranche. Puisque c'est le même \\(W\\), nous allons simplement additionner tous ces gradients pour obtenir \\(dW\\).\n",
    "\n",
    "En code, à l'intérieur des boucles appropriées, cette formule se traduit par :\n",
    "```python\n",
    "dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "```\n",
    "\n",
    "<a name='5-1-3'></a>\n",
    "#### 5.1.3 - Calcul de db :\n",
    "\n",
    "Voici la formule pour calculer \\(db\\) par rapport au coût pour un certain filtre \\(W_c\\) :\n",
    "\n",
    "$$db = \\sum_h \\sum_w dZ_{hw} \\tag{3}$$\n",
    "\n",
    "Comme vous l'avez déjà vu dans les réseaux de neurones de base, \\(db\\) est calculé en sommant \\(dZ\\). Dans ce cas, vous additionnez simplement tous les gradients de la sortie de la couche conv (Z) par rapport au coût.\n",
    "\n",
    "En code, à l'intérieur des boucles appropriées, cette formule se traduit par :\n",
    "```python\n",
    "db[:,:,:,c] += dZ[i, h, w, c]\n",
    "```\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Exercice 5 - conv_backward\n",
    "\n",
    "Implémentez la fonction `conv_backward` ci-dessous. Vous devez sommer tous les exemples d'entraînement, filtres, hauteurs et largeurs. Vous devrez ensuite calculer les dérivées en utilisant les formules 1, 2 et 3 ci-dessus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac01f3e4e6f7707fb3153d5306020619",
     "grade": false,
     "grade_id": "cell-651d7957ed306d8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implémenter la propagation arrière pour une fonction de convolution.\n",
    "    \n",
    "    Arguments :\n",
    "    dZ -- gradient du coût par rapport à la sortie de la couche de convolution (Z), tableau numpy de forme (m, n_H, n_W, n_C)\n",
    "    cache -- cache des valeurs nécessaires pour conv_backward(), sortie de conv_forward()\n",
    "    \n",
    "    Retourne :\n",
    "    dA_prev -- gradient du coût par rapport à l'entrée de la couche de convolution (A_prev),\n",
    "               tableau numpy de forme (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    dW -- gradient du coût par rapport aux poids de la couche de convolution (W)\n",
    "          tableau numpy de forme (f, f, n_C_prev, n_C)\n",
    "    db -- gradient du coût par rapport aux biais de la couche de convolution (b)\n",
    "          tableau numpy de forme (1, 1, 1, n_C)\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Récupérer les informations du \"cache\"\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    # Récupérer les dimensions de A_prev\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    # Récupérer les dimensions de W\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Récupérer les informations des \"hparameters\"\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Récupérer les dimensions de dZ\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    # Initialiser dA_prev, dW, db avec les bonnes dimensions\n",
    "    dA_prev = np.zeros(A_prev.shape)                          \n",
    "    dW = np.zeros(W.shape)\n",
    "    db = np.zeros(b.shape)  # b.shape = [1,1,1,n_C]\n",
    "    \n",
    "    # Ajouter un padding à A_prev et dA_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):  # boucle sur les exemples d'entraînement\n",
    "        \n",
    "        # Sélectionner l'exemple d'entraînement i de A_prev_pad et dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        da_prev_pad = dA_prev_pad[i]\n",
    "        \n",
    "        for h in range(n_H):  # boucle sur l'axe vertical de la sortie\n",
    "            for w in range(n_W):  # boucle sur l'axe horizontal de la sortie\n",
    "                for c in range(n_C):  # boucle sur les canaux de la sortie\n",
    "                    \n",
    "                    # Trouver les coins du \"slice\" courant\n",
    "                    vert_start = stride * h \n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = stride * w\n",
    "                    horiz_end = horiz_start + f\n",
    "\n",
    "                    # Utiliser les coins pour définir le \"slice\" de a_prev_pad\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Mettre à jour les gradients pour la fenêtre et les paramètres du filtre en utilisant les formules données ci-dessus\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        # Mettre dA_prev de l'exemple d'entraînement i à da_prev_pad sans padding (Astuce : utiliser X[pad:-pad, pad:-pad, :])\n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    # S'assurer que la forme de la sortie est correcte\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa7b07d566b435decefd8c5bd1b5c4db",
     "grade": true,
     "grade_id": "cell-ddba321326674547",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_mean = 1.4524377775388075\n",
      "dW_mean = 1.7269914583139097\n",
      "db_mean = 7.839232564616838\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# We'll run conv_forward to initialize the 'Z' and 'cache_conv\",\n",
    "# which we'll use to test the conv_backward function\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10, 4, 4, 3)\n",
    "W = np.random.randn(2, 2, 3, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "\n",
    "# Test conv_backward\n",
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))\n",
    "\n",
    "assert type(dA) == np.ndarray, \"Output must be a np.ndarray\"\n",
    "assert type(dW) == np.ndarray, \"Output must be a np.ndarray\"\n",
    "assert type(db) == np.ndarray, \"Output must be a np.ndarray\"\n",
    "assert dA.shape == (10, 4, 4, 3), f\"Wrong shape for dA  {dA.shape} != (10, 4, 4, 3)\"\n",
    "assert dW.shape == (2, 2, 3, 8), f\"Wrong shape for dW {dW.shape} != (2, 2, 3, 8)\"\n",
    "assert db.shape == (1, 1, 1, 8), f\"Wrong shape for db {db.shape} != (1, 1, 1, 8)\"\n",
    "assert np.isclose(np.mean(dA), 1.4524377), \"Wrong values for dA\"\n",
    "assert np.isclose(np.mean(dW), 1.7269914), \"Wrong values for dW\"\n",
    "assert np.isclose(np.mean(db), 7.8392325), \"Wrong values for db\"\n",
    "\n",
    "print(\"\\033[92m All tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            dA_mean\n",
    "        </td>\n",
    "        <td>\n",
    "            1.45243777754\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            dW_mean\n",
    "        </td>\n",
    "        <td>\n",
    "            1.72699145831\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            db_mean\n",
    "        </td>\n",
    "        <td>\n",
    "            7.83923256462\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name='5-2'></a>\n",
    "## 5.2 Couche de Pooling - Passée Arrière\n",
    "\n",
    "Ensuite, implémentons la passe arrière pour la couche de pooling, en commençant par la couche MAX-POOL. Bien qu'une couche de pooling n'ait pas de paramètres à mettre à jour par la rétropropagation, vous devez tout de même rétropropager le gradient à travers la couche de pooling afin de calculer les gradients pour les couches qui se trouvent avant la couche de pooling.\n",
    "\n",
    "<a name='5-2-1'></a>\n",
    "### 5.2.1 Max Pooling - Passée Arrière  \n",
    "\n",
    "Avant de passer à la rétropropagation de la couche de pooling, vous allez créer une fonction auxiliaire appelée `create_mask_from_window()` qui fait ce qui suit :\n",
    "\n",
    "$$ X = \\begin{bmatrix}\n",
    "1 && 3 \\\\\n",
    "4 && 2\n",
    "\\end{bmatrix} \\quad \\rightarrow  \\quad M =\\begin{bmatrix}\n",
    "0 && 0 \\\\\n",
    "1 && 0\n",
    "\\end{bmatrix}\\tag{4}$$\n",
    "\n",
    "Comme vous pouvez le voir, cette fonction crée une matrice \"masque\" qui garde une trace de l'emplacement du maximum dans la matrice. True (1) indique la position du maximum dans X, les autres entrées sont False (0). Vous verrez plus tard que la passe arrière pour le pooling moyen est similaire à cela, mais utilise un masque différent.\n",
    "\n",
    "<a name='ex-6'></a>\n",
    "### Exercice 6 - create_mask_from_window\n",
    "\n",
    "Implémentez `create_mask_from_window()`. Cette fonction sera utile pour la passe arrière du pooling.  \n",
    "Indices :\n",
    "- [np.max()]() peut être utile. Elle calcule le maximum d'un tableau.\n",
    "- Si vous avez une matrice X et un scalaire x : `A = (X == x)` renverra une matrice A de la même taille que X telle que :\n",
    "```\n",
    "A[i,j] = True si X[i,j] = x\n",
    "A[i,j] = False si X[i,j] != x\n",
    "```\n",
    "- Ici, vous n'avez pas besoin de considérer les cas où plusieurs maxima existent dans une matrice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0088c2c652d94afd13fcc4cf81ff5a0",
     "grade": false,
     "grade_id": "cell-75cdfabbbe3c7905",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    \"\"\"\n",
    "    Crée un masque à partir d'une matrice d'entrée x, pour identifier l'élément maximum de x.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- Tableau de forme (f, f)\n",
    "    \n",
    "    Retourne:\n",
    "    mask -- Tableau de la même forme que la fenêtre, contenant un True à la position correspondant à l'élément maximum de x.\n",
    "    \"\"\"    \n",
    "    # (≈1 ligne)\n",
    "    # mask = None\n",
    "    # DÉBUT DE VOTRE CODE\n",
    "    mask = (x == np.max(x))\n",
    "    \n",
    "    # FIN DE VOTRE CODE\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b239ffa3896a12254d087dc617b92a2a",
     "grade": true,
     "grade_id": "cell-83c1f6349c3fc0ad",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask =  [[ True False False]\n",
      " [False False False]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2, 3)\n",
    "mask = create_mask_from_window(x)\n",
    "print('x = ', x)\n",
    "print(\"mask = \", mask)\n",
    "\n",
    "x = np.array([[-1, 2, 3],\n",
    "              [2, -3, 2],\n",
    "              [1, 5, -2]])\n",
    "\n",
    "y = np.array([[False, False, False],\n",
    "     [False, False, False],\n",
    "     [False, True, False]])\n",
    "mask = create_mask_from_window(x)\n",
    "\n",
    "assert type(mask) == np.ndarray, \"Output must be a np.ndarray\"\n",
    "assert mask.shape == x.shape, \"Input and output shapes must match\"\n",
    "assert np.allclose(mask, y), \"Wrong output. The True value must be at position (2, 1)\"\n",
    "\n",
    "print(\"\\033[92m All tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:** \n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "\n",
    "**x =**\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "[[ 1.62434536 -0.61175641 -0.52817175] <br>\n",
    " [-1.07296862  0.86540763 -2.3015387 ]]\n",
    "\n",
    "  </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "<td>\n",
    "mask =\n",
    "</td>\n",
    "<td>\n",
    "[[ True False False] <br>\n",
    " [False False False]]\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourquoi suivre la position du maximum ? C'est parce que c'est cette valeur d'entrée qui a finalement influencé la sortie, et donc le coût. La rétropropagation calcule les gradients par rapport au coût, donc tout ce qui influence le coût final devrait avoir un gradient non nul. Ainsi, la rétropropagation \"propagera\" le gradient en arrière vers cette valeur d'entrée particulière qui a influencé le coût."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-2-2'></a>Voici la traduction exacte du texte :\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2.2 - Average Pooling - Rétropropagation\n",
    "\n",
    "Dans le max pooling, pour chaque fenêtre d'entrée, toute l'\"influence\" sur la sortie provenait d'une seule valeur d'entrée — le maximum. Dans l'average pooling, chaque élément de la fenêtre d'entrée a une influence égale sur la sortie. Ainsi, pour implémenter la rétropropagation, vous allez maintenant implémenter une fonction auxiliaire qui reflète cela.\n",
    "\n",
    "Par exemple, si nous faisions un average pooling dans la passe avant en utilisant un filtre 2x2, alors le masque que vous utiliserez pour la rétropropagation ressemblera à ceci :  \n",
    "$$ dZ = 1 \\quad \\rightarrow  \\quad dZ =\\begin{bmatrix}\n",
    "1/4 && 1/4 \\\\\n",
    "1/4 && 1/4\n",
    "\\end{bmatrix}\\tag{5}$$\n",
    "\n",
    "Cela implique que chaque position dans la matrice $dZ$ contribue de manière égale à la sortie, car dans la passe avant, nous avons pris une moyenne.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercice 7 - distribuer_la_valeur\n",
    "\n",
    "Implémentez la fonction ci-dessous pour distribuer de manière égale une valeur `dz` à travers une matrice de dimension `shape`.\n",
    "\n",
    "\n",
    "\n",
    "[Hint](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ones.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0a0950ce4306fe20c3345f0108a49bb",
     "grade": false,
     "grade_id": "cell-636557cd1667f01b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    \"\"\"\n",
    "    Distributes the input value in the matrix of dimension shape\n",
    "    \n",
    "    Arguments:\n",
    "    dz -- input scalar\n",
    "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
    "    \n",
    "    Returns:\n",
    "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
    "    \"\"\"    \n",
    "    # Retrieve dimensions from shape (≈1 line)\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix (≈1 line)\n",
    "    average = np.prod(shape)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
    "    a = (dz/average)*np.ones(shape)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe23f96c0d977d6414842a72fa08d64d",
     "grade": true,
     "grade_id": "cell-d34048b69372dc03",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed value = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "a = distribute_value(2, (2, 2))\n",
    "print('distributed value =', a)\n",
    "\n",
    "\n",
    "assert type(a) == np.ndarray, \"Output must be a np.ndarray\"\n",
    "assert a.shape == (2, 2), f\"Wrong shape {a.shape} != (2, 2)\"\n",
    "assert np.sum(a) == 2, \"Values must sum to 2\"\n",
    "\n",
    "a = distribute_value(100, (10, 10))\n",
    "assert type(a) == np.ndarray, \"Output must be a np.ndarray\"\n",
    "assert a.shape == (10, 10), f\"Wrong shape {a.shape} != (10, 10)\"\n",
    "assert np.sum(a) == 100, \"Values must sum to 100\"\n",
    "\n",
    "print(\"\\033[92m All tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "distributed_value =\n",
    "</td>\n",
    "<td>\n",
    "[[ 0.5  0.5]\n",
    "<br\\> \n",
    "[ 0.5  0.5]]\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-2-3'></a>\n",
    "\n",
    "### 5.2.3 Mettre en pratique : Rétropropagation de Pooling\n",
    "\n",
    "Vous avez maintenant tout ce dont vous avez besoin pour calculer la rétropropagation sur une couche de pooling.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercice 8 - pool_backward\n",
    "\n",
    "Implémentez la fonction `pool_backward` dans les deux modes (`\"max\"` et `\"average\"`). Vous utiliserez à nouveau 4 boucles `for` (itérant sur les exemples d'entraînement, la hauteur, la largeur et les canaux). Vous devez utiliser une instruction `if/elif` pour vérifier si le mode est égal à `'max'` ou `'average'`. Si le mode est égal à `'average'`, vous devez utiliser la fonction `distribute_value()` que vous avez implémentée ci-dessus pour créer une matrice de la même forme que `a_slice`. Sinon, le mode est égal à `'max'`, et vous devrez créer un masque avec `create_mask_from_window()` et le multiplier par la valeur correspondante de `dA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "857929f83e0cff037571a794aff714de",
     "grade": false,
     "grade_id": "cell-46629e8e78d1ac80",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implémente la rétropropagation de la couche de pooling\n",
    "    \n",
    "    Arguments :\n",
    "    dA -- gradient de la fonction de coût par rapport à la sortie de la couche de pooling, même forme que A\n",
    "    cache -- cache de la sortie de la propagation avant de la couche de pooling, contient l'entrée de la couche et les hyperparamètres\n",
    "    mode -- le mode de pooling que vous souhaitez utiliser, défini comme une chaîne de caractères (\"max\" ou \"average\")\n",
    "    \n",
    "    Retourne :\n",
    "    dA_prev -- gradient de la fonction de coût par rapport à l'entrée de la couche de pooling, même forme que A_prev\n",
    "    \"\"\"\n",
    "    # Récupérer les informations depuis le cache (≈1 ligne)\n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "    # Récupérer les hyperparamètres de \"hparameters\" (≈2 lignes)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    \n",
    "    # Récupérer les dimensions de A_prev et dA (≈2 lignes)\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "    \n",
    "    # Initialiser dA_prev avec des zéros (≈1 ligne)\n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "    \n",
    "    for i in range(m):  # boucle sur les exemples d'entraînement\n",
    "        \n",
    "        # Sélectionner un exemple d'entraînement depuis A_prev (≈1 ligne)\n",
    "        a_prev = A_prev[i,:,:,:]\n",
    "        \n",
    "        for h in range(n_H):  # boucle sur l'axe vertical\n",
    "            for w in range(n_W):  # boucle sur l'axe horizontal\n",
    "                for c in range(n_C):  # boucle sur les canaux (profondeur)\n",
    "        \n",
    "                    # Trouver les coins du \"slice\" actuel (≈4 lignes)\n",
    "                    vert_start  = h * stride\n",
    "                    vert_end    = h * stride + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end   = w * stride + f\n",
    "                    \n",
    "                    # Calculer la rétropropagation dans les deux modes.\n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                        # Utiliser les coins et \"c\" pour définir le slice actuel de a_prev (≈1 ligne)\n",
    "                        a_prev_slice = a_prev[ vert_start:vert_end, horiz_start:horiz_end, c ]\n",
    "                        \n",
    "                        # Créer le masque à partir de a_prev_slice (≈1 ligne)\n",
    "                        mask = create_mask_from_window( a_prev_slice )\n",
    "\n",
    "                        # Mettre à jour dA_prev en ajoutant (le masque multiplié par l'entrée correspondante de dA) (≈1 ligne)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += mask * dA[i, h, w, c]\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        \n",
    "                        # Obtenir la valeur da depuis dA (≈2 lignes)\n",
    "                        da = dA[i, h, w, c]\n",
    "                        \n",
    "                        # Définir la forme du filtre comme fxf (≈1 ligne)\n",
    "                        shape = (f,f)\n",
    "\n",
    "                        # La distribuer pour obtenir le bon slice de dA_prev. C'est-à-dire ajouter la valeur distribuée de da. (≈1 ligne)\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
    "    \n",
    "    # Vérifier que la forme de la sortie est correcte\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeae810027f56d8418e9a89d7feec967",
     "grade": true,
     "grade_id": "cell-bf176d59f19c3cba",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 2, 2)\n",
      "(5, 5, 3, 2)\n",
      "mode = max\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev1[1,1] =  [[ 0.          0.        ]\n",
      " [ 5.05844394 -1.68282702]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "mode = average\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev2[1,1] =  [[ 0.08485462  0.2787552 ]\n",
      " [ 1.26461098 -0.25749373]\n",
      " [ 1.17975636 -0.53624893]]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "hparameters = {\"stride\" : 1, \"f\": 2}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(A.shape)\n",
    "print(cache[0].shape)\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "\n",
    "dA_prev1 = pool_backward(dA, cache, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev1[1,1] = ', dA_prev1[1, 1])  \n",
    "print()\n",
    "dA_prev2 = pool_backward(dA, cache, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev2[1,1] = ', dA_prev2[1, 1]) \n",
    "\n",
    "assert type(dA_prev1) == np.ndarray, \"Wrong type\"\n",
    "assert dA_prev1.shape == (5, 5, 3, 2), f\"Wrong shape {dA_prev1.shape} != (5, 5, 3, 2)\"\n",
    "assert np.allclose(dA_prev1[1, 1], [[0, 0], \n",
    "                                    [ 5.05844394, -1.68282702],\n",
    "                                    [ 0, 0]]), \"Wrong values for mode max\"\n",
    "assert np.allclose(dA_prev2[1, 1], [[0.08485462,  0.2787552], \n",
    "                                    [1.26461098, -0.25749373], \n",
    "                                    [1.17975636, -0.53624893]]), \"Wrong values for mode average\"\n",
    "print(\"\\033[92m All tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "mode = max:\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "\n",
    "**mean of dA =**\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "0.145713902729\n",
    "\n",
    "  </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "<td>\n",
    "dA_prev[1,1] =\n",
    "</td>\n",
    "<td>\n",
    "[[ 0.          0.        ] <br>\n",
    " [ 5.05844394 -1.68282702] <br>\n",
    " [ 0.          0.        ]]\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "mode = average\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "\n",
    "mean of dA =\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "0.145713902729\n",
    "\n",
    "  </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "<td>\n",
    "dA_prev[1,1] =\n",
    "</td>\n",
    "<td>\n",
    "[[ 0.08485462  0.2787552 ] <br>\n",
    " [ 1.26461098 -0.25749373] <br>\n",
    " [ 1.17975636 -0.53624893]]\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Félicitations** ! Vous avez terminé l'exercice ainsi que la partie optionnelle. Vous comprenez maintenant comment fonctionnent les réseaux neuronaux convolutifs (CNN) et avez implémenté tous les éléments fondamentaux d'un réseau neuronal. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "qO8ng",
   "launcher_item_id": "7XDi8"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
